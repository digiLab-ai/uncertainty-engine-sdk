{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6392db1",
   "metadata": {},
   "source": [
    "# Uncertainty Engine SDK example workflows - Train\n",
    "\n",
    "This notebook goes through how you would set up a workflow to train and save a machine-learning model using the `Train Model` node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a334f5",
   "metadata": {},
   "source": [
    "Start by importing and initializing the `Client` (for more details about the client see the `demo_node.ipynb` example). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf999f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainty_engine.client import Client\n",
    "\n",
    "client = Client(\n",
    "    email=\"<you-email>\",  # Note: There must be token associated with this email.\n",
    "    deployment=\"<a-deployment-url>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dd74d8",
   "metadata": {},
   "source": [
    "## Viewing the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef237c09",
   "metadata": {},
   "source": [
    "Once you have initialised the Uncertainty Engine client you can use the `list_nodes` method to list available nodes under a particular category. In this case we are training a machine learning model, so we can list the nodes under the `MachineLearningModels` category to find the `TrainModel` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d608d0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Add',\n",
      " 'AnalyseVariance',\n",
      " 'AppendDataset',\n",
      " 'BuildSensorDesigner',\n",
      " 'CoralScop',\n",
      " 'CreateChat',\n",
      " 'CreateDatasetSlice',\n",
      " 'CreateFEM',\n",
      " 'CustomPython',\n",
      " 'Dict',\n",
      " 'Display',\n",
      " 'Download',\n",
      " 'EmbeddingsConfig',\n",
      " 'FilterDataset',\n",
      " 'GetContext',\n",
      " 'Join',\n",
      " 'KaustWP6PH',\n",
      " 'LLMConfig',\n",
      " 'Load',\n",
      " 'LoadChatHistory',\n",
      " 'LoadDataset',\n",
      " 'LoadDocument',\n",
      " 'LoadModel',\n",
      " 'LoadMultiple',\n",
      " 'Message',\n",
      " 'ModelConfig',\n",
      " 'Number',\n",
      " 'PcdProcessing',\n",
      " 'PredictModel',\n",
      " 'PromptLLM',\n",
      " 'Recommend',\n",
      " 'Save',\n",
      " 'ScoreModel',\n",
      " 'ScoreSensorDesign',\n",
      " 'SimpleLLM',\n",
      " 'Splitter',\n",
      " 'StereoReconstruction',\n",
      " 'SuggestSensorDesign',\n",
      " 'Text',\n",
      " 'TrainModel',\n",
      " 'UncertaintyPlot',\n",
      " 'Workflow']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "nodes = client.list_nodes()\n",
    "nodes_by_id = {node[\"id\"]: node for node in nodes}\n",
    "\n",
    "pprint(sorted(nodes_by_id.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c954692",
   "metadata": {},
   "source": [
    "Once you have found your `TrainModel` node it can be useful to print out some of the extra information such as `description`, `inputs` and `outputs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d987377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cache_url': 'redis-13325.c338.eu-west-2-1.ec2.redns.redis-cloud.com',\n",
      " 'category': 'MachineLearningModels',\n",
      " 'cost': 5,\n",
      " 'description': 'Train a machine-learning model',\n",
      " 'id': 'TrainModel',\n",
      " 'image_name': 'uncertainty-engine-train-model-node',\n",
      " 'inputs': {'config': {'default': None,\n",
      "                       'description': 'Configuration for the model',\n",
      "                       'label': 'Model Config',\n",
      "                       'required': True,\n",
      "                       'set_in_node': False,\n",
      "                       'type': 'ModelConfig'},\n",
      "            'inputs': {'default': None,\n",
      "                       'description': 'Input dataset for training the model',\n",
      "                       'label': 'Input Dataset',\n",
      "                       'required': True,\n",
      "                       'set_in_node': True,\n",
      "                       'type': 'CSVDataset'},\n",
      "            'outputs': {'default': None,\n",
      "                        'description': 'Output dataset for training the model',\n",
      "                        'label': 'Output Dataset',\n",
      "                        'required': True,\n",
      "                        'set_in_node': True,\n",
      "                        'type': 'CSVDataset'}},\n",
      " 'label': 'Train Model',\n",
      " 'load_balancer_url': 'http://uncert-LoadB-Ld43k6t2BH88-170883323.eu-west-2.elb.amazonaws.com',\n",
      " 'long_description': 'Trains a Gaussian Process model on the input data.',\n",
      " 'outputs': {'model': {'description': 'A trained machine-learning model',\n",
      "                       'label': 'Machine Learning Model',\n",
      "                       'type': 'MachineLearningModel'}},\n",
      " 'queue_url': 'https://sqs.eu-west-2.amazonaws.com/939027885851/uncertainty-engine-train-model-node-dev-Queue-r13fW9mEIpdi',\n",
      " 'requirements': {'cpu': 8192, 'gpu': False, 'memory': 16384, 'timeout': 1200},\n",
      " 'version_base_image': 2,\n",
      " 'version_node': 1,\n",
      " 'version_types_lib': '0.0.14'}\n"
     ]
    }
   ],
   "source": [
    "train_node = nodes_by_id[\"TrainModel\"]\n",
    "\n",
    "pprint(train_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097715e6",
   "metadata": {},
   "source": [
    "Now we have that information we can start to build our workflow using the right nodes and its inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465b463",
   "metadata": {},
   "source": [
    "## Constructing your train workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73c79a",
   "metadata": {},
   "source": [
    "First, import and initialize the `Graph` object and add the `TrainModel` node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f36888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainty_engine.graph import Graph\n",
    "from uncertainty_engine.nodes.base import Node\n",
    "\n",
    "graph = Graph()\n",
    "\n",
    "train_model = Node(\n",
    "    node_name=\"TrainModel\"\n",
    ")\n",
    "\n",
    "graph.add_node(train_model, \"Train Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e09f2a",
   "metadata": {},
   "source": [
    "As we can see by the `TrainModel` node we know that it needs a model config. When viewing the `MachineLearningModel` nodes we can see that there is a `ModelConfig` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bbba59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_retained_dimensions': {'default': None,\n",
      "                               'description': 'Number of dimensions to retain '\n",
      "                                              'in the input data',\n",
      "                               'label': 'Input Retained Dimensions',\n",
      "                               'required': False,\n",
      "                               'set_in_node': True,\n",
      "                               'type': 'int'},\n",
      " 'input_variance': {'default': None,\n",
      "                    'description': 'Percentage of variance to retain in the '\n",
      "                                   'input data',\n",
      "                    'label': 'Input Variance',\n",
      "                    'required': False,\n",
      "                    'set_in_node': True,\n",
      "                    'type': 'float'},\n",
      " 'model_type': {'default': 'SingleTaskGPTorch',\n",
      "                'description': 'Type of model to use',\n",
      "                'label': 'Model Type',\n",
      "                'required': False,\n",
      "                'set_in_node': True,\n",
      "                'type': 'Literal[\"SingleTaskGPTorch\"]'},\n",
      " 'output_retained_dimensions': {'default': None,\n",
      "                                'description': 'Number of dimensions to retain '\n",
      "                                               'in the output data',\n",
      "                                'label': 'Output Retained Dimensions',\n",
      "                                'required': False,\n",
      "                                'set_in_node': True,\n",
      "                                'type': 'int'},\n",
      " 'output_variance': {'default': None,\n",
      "                     'description': 'Percentage of variance to retain in the '\n",
      "                                    'output data',\n",
      "                     'label': 'Output Variance',\n",
      "                     'required': False,\n",
      "                     'set_in_node': True,\n",
      "                     'type': 'float'},\n",
      " 'seed': {'default': None,\n",
      "          'description': 'Seed for  reproducible training',\n",
      "          'label': 'Seed',\n",
      "          'required': False,\n",
      "          'set_in_node': True,\n",
      "          'type': 'Optional[int]'}}\n",
      "{'config': {'description': 'A model config object',\n",
      "            'label': 'Model Config',\n",
      "            'type': 'ModelConfig'}}\n"
     ]
    }
   ],
   "source": [
    "model_config_info = nodes_by_id[\"ModelConfig\"]\n",
    "\n",
    "pprint(model_config_info[\"inputs\"])\n",
    "pprint(model_config_info[\"outputs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c4eee",
   "metadata": {},
   "source": [
    "Now we can define our `ModelConfig` node. As none of the inputs are required we can just use the default input parameters for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab0a91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = Node(\n",
    "    node_name=\"ModelConfig\",\n",
    "    label=\"Model Config\",\n",
    ")\n",
    "\n",
    "graph.add_node(model_config)\n",
    "\n",
    "graph.add_edge(\n",
    "    source=\"Model Config\",\n",
    "    target=\"Train Model\",\n",
    "    source_key=\"config\",\n",
    "    target_key=\"config\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a93f2",
   "metadata": {},
   "source": [
    "The other input parameters we need are the input (`X`) and output (`y`) datasets. We can use the `quickstart` example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "627bbafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/quickstart.csv\", \"r\") as file:\n",
    "    quickstart_csv = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "040c52a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'columns': {'default': None,\n",
      "             'description': 'The list of columns to keep',\n",
      "             'label': 'Columns',\n",
      "             'required': True,\n",
      "             'set_in_node': True,\n",
      "             'type': 'list[str]'},\n",
      " 'dataset': {'default': None,\n",
      "             'description': 'The dataset to filter',\n",
      "             'label': 'Dataset',\n",
      "             'required': True,\n",
      "             'set_in_node': False,\n",
      "             'type': 'CSVDataset'}}\n",
      "{'dataset': {'description': 'The filtered dataset',\n",
      "             'label': 'Dataset',\n",
      "             'type': 'CSVDataset'}}\n"
     ]
    }
   ],
   "source": [
    "model_config_info = nodes_by_id[\"FilterDataset\"]\n",
    "\n",
    "pprint(model_config_info[\"inputs\"])\n",
    "pprint(model_config_info[\"outputs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be50af25",
   "metadata": {},
   "source": [
    "We can split our dataset using the `FilterDataset` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "782f1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dataset1 = Node(\n",
    "    node_name=\"FilterDataset\",\n",
    "    dataset={\"csv\": quickstart_csv},\n",
    "    columns=[\"x\"]\n",
    ")\n",
    "\n",
    "filter_dataset2 = Node(\n",
    "    node_name=\"FilterDataset\",\n",
    "    dataset={\"csv\": quickstart_csv},\n",
    "    columns=[\"y\"]\n",
    ")\n",
    "\n",
    "graph.add_node(filter_dataset1, \"Input\")\n",
    "graph.add_node(filter_dataset2, \"Output\")\n",
    "\n",
    "graph.add_edge(\n",
    "    source=\"Input\",\n",
    "    target=\"Train Model\",\n",
    "    source_key=\"dataset\",\n",
    "    target_key=\"inputs\"\n",
    ")\n",
    "\n",
    "graph.add_edge(\n",
    "    source=\"Output\",\n",
    "    target=\"Train Model\",\n",
    "    source_key=\"dataset\",\n",
    "    target_key=\"outputs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc869de",
   "metadata": {},
   "source": [
    "Now we have all our inputs for `TrainModel` we can use `graph.node` to list our nodes in graph format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ef6c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': {'Input': {'inputs': {'columns': {'node_handle': 'Input_columns',\n",
      "                                            'node_name': '_'},\n",
      "                                'dataset': {'node_handle': 'Input_dataset',\n",
      "                                            'node_name': '_'}},\n",
      "                     'type': 'FilterDataset'},\n",
      "           'Model Config': {'inputs': {}, 'type': 'ModelConfig'},\n",
      "           'Output': {'inputs': {'columns': {'node_handle': 'Output_columns',\n",
      "                                             'node_name': '_'},\n",
      "                                 'dataset': {'node_handle': 'Output_dataset',\n",
      "                                             'node_name': '_'}},\n",
      "                      'type': 'FilterDataset'},\n",
      "           'Train Model': {'inputs': {'config': {'node_handle': 'config',\n",
      "                                                 'node_name': 'Model Config'},\n",
      "                                      'inputs': {'node_handle': 'dataset',\n",
      "                                                 'node_name': 'Input'},\n",
      "                                      'outputs': {'node_handle': 'dataset',\n",
      "                                                  'node_name': 'Output'}},\n",
      "                           'type': 'TrainModel'}}}\n"
     ]
    }
   ],
   "source": [
    "pprint(graph.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d74d1",
   "metadata": {},
   "source": [
    "## Defining node outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a91e5",
   "metadata": {},
   "source": [
    "Now are graph has been built we can use an output node to decide how we wish to collect the output. In this case we would like to download our output using the `Download` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d416840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': {'Download': {'inputs': {'file': {'node_handle': 'model',\n",
      "                                            'node_name': 'Train Model'}},\n",
      "                        'type': 'Download'},\n",
      "           'Input': {'inputs': {'columns': {'node_handle': 'Input_columns',\n",
      "                                            'node_name': '_'},\n",
      "                                'dataset': {'node_handle': 'Input_dataset',\n",
      "                                            'node_name': '_'}},\n",
      "                     'type': 'FilterDataset'},\n",
      "           'Model Config': {'inputs': {}, 'type': 'ModelConfig'},\n",
      "           'Output': {'inputs': {'columns': {'node_handle': 'Output_columns',\n",
      "                                             'node_name': '_'},\n",
      "                                 'dataset': {'node_handle': 'Output_dataset',\n",
      "                                             'node_name': '_'}},\n",
      "                      'type': 'FilterDataset'},\n",
      "           'Train Model': {'inputs': {'config': {'node_handle': 'config',\n",
      "                                                 'node_name': 'Model Config'},\n",
      "                                      'inputs': {'node_handle': 'dataset',\n",
      "                                                 'node_name': 'Input'},\n",
      "                                      'outputs': {'node_handle': 'dataset',\n",
      "                                                  'node_name': 'Output'}},\n",
      "                           'type': 'TrainModel'}}}\n"
     ]
    }
   ],
   "source": [
    "download = Node(\n",
    "  node_name=\"Download\",\n",
    "  label=\"Download\"\n",
    ")\n",
    "\n",
    "graph.add_node(download)\n",
    "\n",
    "graph.add_edge(\n",
    "    source=\"Train Model\",\n",
    "    target=\"Download\",\n",
    "    source_key=\"model\",\n",
    "    target_key=\"file\"\n",
    ")\n",
    "\n",
    "pprint(graph.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575839d0",
   "metadata": {},
   "source": [
    "## Executing a workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc75f1e",
   "metadata": {},
   "source": [
    "Create the executable workflow by wrapping our graph in the `Workflow` node and defining the `requested_output` as the output handle of the `Download` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8776c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainty_engine.nodes.workflow import Workflow\n",
    "\n",
    "workflow = Workflow(\n",
    "    graph=graph.nodes,\n",
    "    input=graph.external_input,\n",
    "    external_input_id=graph.external_input_id,\n",
    "    requested_output={\n",
    "        \"Trained Model\": {\"node_name\":\"Download\", \"node_handle\":\"file\"},\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249edb3b",
   "metadata": {},
   "source": [
    "Execute the workflow bu running `client.run_node(workflow)` and passing the workflow object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d560a205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputs': {'Trained Model': 'https://uncertainty-engine-download-node-dev-databucket-b4nubppbi7hc.s3.amazonaws.com/7555e5ae-1a6c-426b-9e1a-740edd6c1c9f/17f20130-26d5-4161-9842-715af9c80178/content.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIA5VITMN4NQIMDQXFJ%2F20250519%2Feu-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250519T140032Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjENb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCWV1LXdlc3QtMiJHMEUCIQD2dftr%2FtgjZPGhaaUbAYa2evEtg7RvOkjoPkFOyGTRbQIgfbwqYKzvvaFS1zJNJz2Frd3b4lRgECi7rQLpEGxa5FYqvgQIj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw5MzkwMjc4ODU4NTEiDBkq37jbBYjd%2Bde3SSqSBFjcJKmeUWW0nyuolPDMdCcI43%2FyGGPUlR0VKH9RgBwmK40qzUotmO6mzMO%2BkpSVtvySK6EC3DvkYdDSpjvPh6R6tsQxC%2FsGAnQHBMcTgu5FSS%2FW4CIWrQME8UdUpSl1fgn6ej30buIVxnIVUKUl2ShW4hpCCo5l4IQ7Qw1s7UHdBoxq90KgXrnwt5dAtvmvmCqM6XVbmIb%2BzEnmrHGbPv5nweLa0M21OpV5OeFoEHyhEhQ0IY5wdis6CID2ueZpzqewK%2FmprcA6Jt%2F0ejNl5BX%2BPx6zxUzvFgH5d8jgnh8M89nyFOKWGcs078M7xlNvmQttWb1uHOglid8q%2BOGm8cqJ7kn8H6Lnb4EQ26p45ac9aS165PmbeyfeA5WMCXB08Wl7OO3rq3naItJVfZSpTYwSm4AX1ppzN%2Bg8jpKtAjlkIPiw21oX2spowlSBkR28qa7B5iG1%2BgRU%2FYBZrK2NAgGU8iIJxBVgZySnvhQaJY9dHRIJOSd6QQI5msDcQs6%2FlHv5%2FRk4UW2ZVlHXSogiseIc%2Bo5nmrt%2FwN%2BXFQNAtNeAHq%2F5S7Oi%2BAnwQdXvypyhhEc18HRLV6t3dy%2FyPbXTgpJbDa6j0xgQR6bKEGJORTNhj%2Fc8OS2Zj%2BDe4uK0qK2EJZLSCHzFvEszaRBsIKmS9CCNwFFrAHKlIM1CLLpceBmlPgJ6%2BTsww5CcLfvsdw0hwfEVMIbtrMEGOqYBclLfIs1wNa1WSLUf%2FGvKhZaPi6o0vQaUjWf67rv7gSORh%2B4WXrC4URA%2FBTBA6JGfKj2OSr6uF1ugDvMv29ICz9tulyxja95MinVfQIjuFcda7T%2FGtxniBSDSfrN5%2FLMJ2sIkSjd30tKt5D2NzCSM7L3qtpaI%2FNr1aqMhHbSEfO5Qi7sg1nEL2VxnAUBfgO8GxhGfMDPB7tdTEOlvTme0ezHxT3x2ZA%3D%3D&X-Amz-Signature=7012532dde12c6440506baec60c525634d307c6cd3ebd6719e82af64dd845407'}}\n"
     ]
    }
   ],
   "source": [
    "response = client.run_node(workflow)\n",
    "pprint(response[\"outputs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9646b7e",
   "metadata": {},
   "source": [
    "Following the presigned URL will download the trained model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
